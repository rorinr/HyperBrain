 - Use pixel correspondences extracted from SfM reconstructions ([[Annotations/D2Net#^uarad735kq]])
- Recent approaches (mostly detect-than-describe) perform poorly under extreme appearance changes. Reason for that is the lack of repeatability in the keypoint detector: descriptors tend to consider larger patches/high-level structures. Keypoint-detectors only consider smaller image regions ([[Annotations/D2Net#^kwt4mat1g1]])
- Detectors on the other hand are more reliable. Therefore approaches that avoid the detection stage but densely extract descriptors perform better in challenging conditions ([[Annotations/D2Net#^sj84cca2i7]])
- New approach is not detect-than-describe but describe-and-detect. This yields in a feature detector which is tightly coupled with the feature descriptor and both of the using (more or less) the same high-level information ([[Annotations/D2Net#^bbn0zd2ggm8]])
- Map image to a 3D tensor of HxWxN. We can interpret each description vector d_ij as feature describing the corresponding pixel ([[Annotations/D2Net#^jj3174hecr]])
- Another interpretation: N different feature detector function, each producing a 2D response map ([[Annotations/D2Net#^lrz1o49txbs]])
- Hard feature detection: Requirement for a detecting a point: point must be local maximum in D_k (k'th 2D response) with k = maximum argument inside the N-dimension detection vector d_ij ([[Annotations/D2Net#^jw2qg4ryb9a]])
- To enable this hard feature detection during training, they used a soft feature detection. There the 3D tensor is reduced to a 2D image response ([[Annotations/D2Net#^chfaomy68wf]])
- They trained with an extended version of the triplet margin ranking loss = max (0, M + p(c)²-n(c)²), where p is the positive descriptor distance between 2 corresponding descriptors (should be as small as possible) and n is the negative distance, should be high to allow distinctiveness of descriptors. The negative distance comes from the hardest negative samples, ie which are most probable to be confused with positive pairs ([[Annotations/D2Net#^oxvzusenz4f]])
- They also added a detection term for better repeatability ([[Annotations/D2Net#^upd8f3qo26s]])
- D2Net perform worse than detect-then-describe approaches for stricter thresholds. The reason is that D2Net learns higher-level features instead of low-level blob-like structures, which are better localized ([[Annotations/D2Net#^9f5b87g8ygt]]) 
- 
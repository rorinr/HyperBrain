- Jointly matches sparse points and rejects outliers [[Annotations/LightGlue#^kia80aefbeg]]
- Robustness vs. uniqueness: conflicting goals in image feature matching. Robustness means the algorithm can still match features accurately under tough conditions like poor lighting or similar looking areas. Uniqueness means each feature is distinct enough to be accurately identified. The conflict arises because making an algorithm robust (tolerant to changes) can reduce its ability to identify unique features (focus on specific details), and vice versa. It is a trade-off because if you allow the algorithm to ignore minor changes (which is needed for occlusions) you also reduce its uniqueness at the same time (ignore minor changes of symmetric features can yield in confusion) [[Annotations/LightGlue#^iuelfmuuji]]
- LightGlue is adaptive to the difficulty of each image pair, which means it computes at each computational block whether further computation is required [[Annotations/LightGlue#^i8lxhaq1kbd]]
- **Sparse Matchers**: These matchers focus on a limited number of specific points or features in an image. These points are usually distinctive or notable parts of the image, like corners or edges. Sparse matchers are generally faster because they process fewer points. However, they might miss some details because they ignore most of the image's area.
  **Dense Matchers**: In contrast, dense matchers analyze points across the entire image, often on a grid-like structure. This approach considers a much larger number of points, providing a more comprehensive analysis of the image. As a result, dense matchers can be more robust to variations and can capture more details. The downside is that they are generally slower due to processing many more elements, and they might require lower resolution images to manage the computational load. [[Annotations/LightGlue#^do8mk08c0gg]]
- A local feature consists of a normalized 2D point position (pixel position) and a visual descriptor [[Annotations/LightGlue#^x5ttf4do4t8]]
- Matrix P gives the confidence that feature i (from image A) matches with feature j (from image B) [[Annotations/LightGlue#^kg1k04m8cq]]
- LightGlue uses a stack of identical layers, each with self- and cross-attention units to update point representations, and employs a classifier for efficient inference halting (decide if we are able to leave inference early) and a lightweight head to compute partial assignments from these representations. [[Annotations/LightGlue#^jxxllnz0ha]]
- Each local feature i is associated with a state x_i. This is initialized with the corresponding visual descriptor [[Annotations/LightGlue#^ueainw0khs]]
- This state is updated with a concatenation of itself and a message m_i, followed by a MLP [[Annotations/LightGlue#^8u4lqbs5yzn]])
- This message m_i is computed using the state x_i and attention score a_ik. The attention score a_ij which differs for self- and cross-attention [[Annotations/LightGlue#^yyv9295zdwp]]
- They used rotary encoding for the self-attention layer, which means that we compare features/position coming from the same image. 

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"c:\\\\Users\\\\robin\\\\Documents\\\\HyperBrain\")\n",
    "sys.path.append(\"c:\\\\Users\\\\robin\\\\Documents\\\\HyperBrain\\\\source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.datasets.brain_dataset import BrainDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from source.lightning.setup_model import setup_lightning_loftr, LitLoFTR\n",
    "import lightning as L\n",
    "from torchvision.transforms import v2\n",
    "from source.datasets.brain_dataset import collate_fn\n",
    "from lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from source.loftr.backbone import ResNetFPN_16_4, ResNetFPN_8_2\n",
    "from source.loftr.positional_encoding import PositionalEncoding\n",
    "from source.loftr.transformer import LocalFeatureTransformer\n",
    "from source.loftr.coarse_matching import CoarseMatching\n",
    "from source.loftr.fine_matching import FineMatching\n",
    "from source.loftr.fine_preprocess import FinePreprocess\n",
    "from source.loftr.loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 640\n",
    "affine_transformation_range = 0.25\n",
    "perspective_transformation_range = 0.0001\n",
    "patch_size = 16\n",
    "max_translation_shift = 50\n",
    "fine_height_width = (crop_size//patch_size)*4\n",
    "coarse_height_width = crop_size//patch_size\n",
    "images_directory = \"../../data/cyto_downscaled_3344_3904/\"\n",
    "use_train_data = True\n",
    "\n",
    "dataset_train = BrainDataset(\n",
    "    images_directory=images_directory,\n",
    "    train=use_train_data,\n",
    "    affine_transformation_range=affine_transformation_range,\n",
    "    perspective_transformation_range=perspective_transformation_range,\n",
    "    crop_size=crop_size,\n",
    "    patch_size=patch_size,\n",
    "    max_translation_shift=max_translation_shift,\n",
    "    fine_height_width=fine_height_width,\n",
    "    transform=v2.Compose([v2.Normalize(mean=[0.594], std=[0.204])]),\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=dataset_train,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    # num_workers=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_dimensions = [64, 96, 128, 192]\n",
    "temperature = 0.2\n",
    "use_coarse_context = False\n",
    "fine_loss = \"l2_std\"\n",
    "\n",
    "\n",
    "backbone = ResNetFPN_8_2(block_dimensions=block_dimensions)\n",
    "fine_feature_size = block_dimensions[0]\n",
    "\n",
    "coarse_feature_size = block_dimensions[-1]\n",
    "\n",
    "positional_encoding = PositionalEncoding(coarse_feature_size)\n",
    "\n",
    "coarse_loftr = LocalFeatureTransformer(\n",
    "feature_dimension=coarse_feature_size,\n",
    "number_of_heads=8,\n",
    "layer_names=[\"self\", \"cross\"] * 4,\n",
    ")\n",
    "\n",
    "coarse_matcher = CoarseMatching(temperature=temperature, confidence_threshold=0.2)\n",
    "\n",
    "fine_preprocess = FinePreprocess(\n",
    "coarse_feature_size=coarse_feature_size,\n",
    "fine_feature_size=fine_feature_size,\n",
    "window_size=5,\n",
    "use_coarse_context=use_coarse_context,\n",
    ")\n",
    "\n",
    "fine_loftr = LocalFeatureTransformer(\n",
    "feature_dimension=fine_feature_size,\n",
    "number_of_heads=8,\n",
    "layer_names=[\"self\", \"cross\"],\n",
    ")\n",
    "\n",
    "use_l2_with_standard_deviation = True if fine_loss == \"l2_std\" else False\n",
    "fine_matching = FineMatching(\n",
    "return_standard_deviation=use_l2_with_standard_deviation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loftr = LitLoFTR.load_from_checkpoint(\"lightning_logs/version_1/checkpoints/epoch=215-step=216.ckpt\", \n",
    "                                      backbone=backbone, positional_encoding=positional_encoding, \n",
    "                                      coarse_loftr=coarse_loftr, coarse_matcher=coarse_matcher, \n",
    "                                      fine_preprocess=fine_preprocess, fine_loftr=fine_loftr, \n",
    "                                      fine_matching=fine_matching, fine_loss=fine_loss, coarse_loss=\"official_focal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [LitLoFTR] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloftr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\robin\\miniconda3\\envs\\superbrain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\robin\\miniconda3\\envs\\superbrain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\robin\\miniconda3\\envs\\superbrain\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:691\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    681\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Same as :meth:`torch.nn.Module.forward`.\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \n\u001b[0;32m    683\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    689\u001b[0m \n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\robin\\miniconda3\\envs\\superbrain\\Lib\\site-packages\\torch\\nn\\modules\\module.py:372\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [LitLoFTR] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "loftr(torch.Tensor([1,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superbrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
